{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/ConsisID-jupyter/blob/main/ConsisID_jupyter.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjYy0F2gZIPR"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python imageio imageio-ffmpeg ffmpeg-python av runpod\n",
    "!pip install torchsde einops diffusers transformers accelerate peft timm kornia scikit-image matplotlib blend-modes segment-anything spandrel wget pydantic aiohttp\n",
    "!git clone https://github.com/comfyanonymous/ComfyUI /content/ComfyUI\n",
    "!git clone https://github.com/ltdrdata/ComfyUI-Manager /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
    "!git clone https://github.com/sipherxyz/comfyui-art-venture /content/ComfyUI/custom_nodes/comfyui-art-venture\n",
    "!git clone https://github.com/chflame163/ComfyUI_LayerStyle /content/ComfyUI/custom_nodes/ComfyUI_LayerStyle\n",
    "!git clone https://github.com/cubiq/ComfyUI_essentials /content/ComfyUI/custom_nodes/ComfyUI_essentials\n",
    "!git clone https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet /content/ComfyUI/custom_nodes/ComfyUI-Advanced-ControlNet\n",
    "!git clone https://github.com/cubiq/ComfyUI_IPAdapter_plus /content/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n",
    "!git clone https://github.com/Fannovel16/comfyui_controlnet_aux /content/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
    "!apt install aria2 -qqy\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/misri/leosamsHelloworldXL_helloworldXL70/resolve/main/leosamsHelloworldXL_helloworldXL70.safetensors -d /content/ComfyUI/models/checkpoints/sdxl -o leosamsHelloworldXL_helloworldXL70.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/alvdansen/midsommarcartoon/resolve/main/araminta_k_midsommar_cartoon.safetensors -d /content/ComfyUI/models/loras/sdxl -o araminta_k_midsommar_cartoon.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/xinsir/controlnet-union-sdxl-1.0/resolve/main/diffusion_pytorch_model_promax.safetensors -d /content/ComfyUI/models/controlnet/sdxl -o controlnet-union-sdxl-1.0-promax.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/yiwangsimple/BiRefNet-general-epoch_244/resolve/main/BiRefNet-general-epoch_244.pth -d /content/ComfyUI/models/BiRefNet/pth -o BiRefNet-general-epoch_244.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl_vit-h.safetensors -d /content/ComfyUI/models/ipadapter -o ip-adapter_sdxl_vit-h.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/sharing1179/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors/resolve/main/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors -d /content/ComfyUI/models/clip_vision -o CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%cd /content/ComfyUI\n",
    "\n",
    "import os, shutil, json, requests, random, time\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from nodes import NODE_CLASS_MAPPINGS, load_custom_node\n",
    "from comfy_extras import  nodes_flux, nodes_differential_diffusion, nodes_model_advanced, nodes_custom_sampler\n",
    "\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/comfyui-art-venture\")\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI_LayerStyle\")\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI_essentials\")\n",
    "load_custom_node(\"/content/ComfyUI/custom_nodes/ComfyUI-Advanced-ControlNet\")\n",
    "\n",
    "CheckpointLoaderSimple = NODE_CLASS_MAPPINGS[\"CheckpointLoaderSimple\"]()\n",
    "LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
    "ACN_ControlNet = NODE_CLASS_MAPPINGS[\"ACN_ControlNet++LoaderSingle\"]()\n",
    "LoadBiRefNetModel = NODE_CLASS_MAPPINGS[\"LayerMask: LoadBiRefNetModel\"]()\n",
    "\n",
    "LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
    "ImageBatch = NODE_CLASS_MAPPINGS[\"ImageBatch\"]()\n",
    "AV_IPAdapter = NODE_CLASS_MAPPINGS[\"AV_IPAdapter\"]()\n",
    "\n",
    "ImageScaleToMegapixels = NODE_CLASS_MAPPINGS[\"ImageScaleToMegapixels\"]()\n",
    "BiRefNetUltraV2 = NODE_CLASS_MAPPINGS[\"LayerMask: BiRefNetUltraV2\"]()\n",
    "ImageRemoveAlpha = NODE_CLASS_MAPPINGS[\"LayerUtility: ImageRemoveAlpha\"]()\n",
    "ImageDesaturate = NODE_CLASS_MAPPINGS[\"ImageDesaturate+\"]()\n",
    "AV_ControlNetPreprocessor = NODE_CLASS_MAPPINGS[\"AV_ControlNetPreprocessor\"]()\n",
    "ControlNetApplyAdvanced = NODE_CLASS_MAPPINGS[\"ControlNetApplyAdvanced\"]()\n",
    "CLIPTextEncode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
    "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
    "GetImageSize = NODE_CLASS_MAPPINGS[\"GetImageSize+\"]()\n",
    "KSampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
    "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    unet, clip, vae = CheckpointLoaderSimple.load_checkpoint(\"sdxl/leosamsHelloworldXL_helloworldXL70.safetensors\")\n",
    "    lora_unet, lora_clip = LoraLoader.load_lora(unet, clip, \"sdxl/araminta_k_midsommar_cartoon.safetensors\", 0.80, 1.0)\n",
    "    control_net = ACN_ControlNet.load_controlnet_plusplus(\"sdxl/controlnet-union-sdxl-1.0-promax.safetensors\", \"canny/lineart/mlsd\")[0]\n",
    "    birefnet_model = LoadBiRefNetModel.load_birefnet_model(\"BiRefNet-general-epoch_244.pth\")[0]\n",
    "\n",
    "def download_file(url, save_dir, file_name):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_suffix = os.path.splitext(urlsplit(url).path)[1]\n",
    "    file_name_with_suffix = file_name + file_suffix\n",
    "    file_path = os.path.join(save_dir, file_name_with_suffix)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    return file_path\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(input):\n",
    "    values = input[\"input\"]\n",
    "\n",
    "    input_image = values['input_image']\n",
    "    input_image = download_file(url=input_image, save_dir='/content/ComfyUI/input', file_name='input_image')\n",
    "    style_image1 = values['style_image1']\n",
    "    style_image1 = download_file(url=style_image1, save_dir='/content/ComfyUI/input', file_name='style_image1')\n",
    "    style_image2 = values['style_image2']\n",
    "    style_image2 = download_file(url=style_image2, save_dir='/content/ComfyUI/input', file_name='style_image2')\n",
    "    style_image3 = values['style_image3']\n",
    "    style_image3 = download_file(url=style_image3, save_dir='/content/ComfyUI/input', file_name='style_image3')\n",
    "    style_image4 = values['style_image4']\n",
    "    style_image4 = download_file(url=style_image4, save_dir='/content/ComfyUI/input', file_name='style_image4')\n",
    "    positive_prompt = values['positive_prompt']\n",
    "    negative_prompt = values['negative_prompt']\n",
    "    seed = values['seed']\n",
    "    steps = values['steps']\n",
    "    cfg = values['cfg']\n",
    "    sampler_name = values['sampler_name']\n",
    "    scheduler = values['scheduler']\n",
    "    width = values['width']\n",
    "    height = values['height']\n",
    "    if seed == 0:\n",
    "        random.seed(int(time.time()))\n",
    "        seed = random.randint(0, 18446744073709551615)\n",
    "    input_image = LoadImage.load_image(input_image)[0]\n",
    "    input_image = ImageScaleToMegapixels.image_scale_down_to_total_pixels(input_image, megapixels=1.0)[0]\n",
    "    input_image, input_mask = BiRefNetUltraV2.birefnet_ultra_v2(input_image, birefnet_model, detail_method=\"VITMatte\", detail_erode=4, detail_dilate=2, black_point=0.01, white_point=0.99, process_detail=False, device=\"cuda\", max_megapixels=2.0)\n",
    "    input_image = ImageRemoveAlpha.image_remove_alpha(input_image, fill_background=True, background_color=\"#FFFFFF\", mask=input_mask)[0]\n",
    "    input_image = ImageDesaturate.execute(input_image, factor=1.0, method=\"luminance (Rec.601)\")[0]\n",
    "    style_image1 = LoadImage.load_image(style_image1)[0]\n",
    "    style_image2 = LoadImage.load_image(style_image2)[0]\n",
    "    style_image3 = LoadImage.load_image(style_image3)[0]\n",
    "    style_image4 = LoadImage.load_image(style_image4)[0]\n",
    "    batch_image1 = ImageBatch.batch(style_image1, style_image2)[0]\n",
    "    batch_image2 = ImageBatch.batch(style_image3, style_image4)[0]\n",
    "    batch_image3 = ImageBatch.batch(batch_image1, batch_image2)[0]\n",
    "    ip_unet = AV_IPAdapter.apply_ip_adapter(\"ip-adapter_sdxl_vit-h.safetensors\", \"CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\", lora_unet, batch_image3, weight=1.5, weight_type=\"style transfer\", start_at=0, end_at=1)[0]\n",
    "    canny_image = AV_ControlNetPreprocessor.detect_controlnet(input_image, preprocessor=\"canny\", sd_version=\"sdxl\", resolution=640, preprocessor_override=\"None\")[0]\n",
    "    positive = CLIPTextEncode.encode(clip, positive_prompt)[0]\n",
    "    negative = CLIPTextEncode.encode(clip, negative_prompt)[0]\n",
    "    positive, negative = ControlNetApplyAdvanced.apply_controlnet(positive, negative, control_net, canny_image, strength=0.65, start_percent=0.0, end_percent=0.91, vae=vae)\n",
    "    latent_image = EmptyLatentImage.generate(width, height, batch_size=1)[0]\n",
    "    samples = KSampler.sample(ip_unet, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=1.0)[0]\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = { \n",
    "        \"input\": {\n",
    "        \"input_image\": \"https://files.catbox.moe/kxihm6.jpg\",\n",
    "        \"style_image1\": \"https://files.catbox.moe/bdzw7s.png\",\n",
    "        \"style_image2\": \"https://files.catbox.moe/59u8q5.png\",\n",
    "        \"style_image3\": \"https://files.catbox.moe/ctpfk2.png\",\n",
    "        \"style_image4\": \"https://files.catbox.moe/gjy7lc.png\",\n",
    "        \"positive_prompt\": \"solo, simple_background, white_background, monochrome, no_humans, robot, mecha, science_fiction\",\n",
    "        \"negative_prompt\": \"blurry\",\n",
    "        \"seed\": 0,\n",
    "        \"steps\": 20,\n",
    "        \"cfg\": 5.3,\n",
    "        \"sampler_name\": \"dpmpp_sde\",\n",
    "        \"scheduler\": \"karras\",\n",
    "        \"width\": 1024,\n",
    "        \"height\": 1024\n",
    "    }\n",
    "}\n",
    "samples = generate(input)\n",
    "torch.save(samples, \"/content/samples.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Free T4 Restart at this point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/ComfyUI\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from nodes import NODE_CLASS_MAPPINGS\n",
    "\n",
    "CheckpointLoaderSimple = NODE_CLASS_MAPPINGS[\"CheckpointLoaderSimple\"]()\n",
    "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
    "\n",
    "with torch.inference_mode():\n",
    "  _, _, vae = CheckpointLoaderSimple.load_checkpoint(\"sdxl/leosamsHelloworldXL_helloworldXL70.safetensors\")\n",
    "  samples = torch.load(\"/content/samples.pt\")\n",
    "  decoded = VAEDecode.decode(vae, samples)[0].detach()\n",
    "  image = Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(f\"/content/sdxl-line-art-style-transfer.png\")\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
